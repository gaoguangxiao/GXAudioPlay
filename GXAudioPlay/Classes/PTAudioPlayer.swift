//
//  PTAudioPlayer.swift
//  KidReading
//
//  Created by zoe on 2019/8/20.
//  Copyright Â© 2019 putao. All rights reserved.
//

import Foundation
import AVFoundation
import CoreMedia
import RxCocoa
import RxSwift

public class PTAudioPlayer: NSObject {
    
    public static let shared = PTAudioPlayer()
    
    /// An instance object of AVPlayer
    private var remoteAudioPlayer: AVPlayer?
    
    public var playEventsBlock: ((PTAudioPlayerEvent)->())?
    
    var status : PTAudioPlayerEvent = .None
    
    private var disposeBag = DisposeBag()
    //æ’­æ”¾å™¨é€Ÿåº¦
    public var playSpeed: Float = 1.0
    //æ’­æ”¾å™¨éŸ³é‡
    public var volume: Float = 1.0 {
        didSet {
            remoteAudioPlayer?.volume = volume
        }
    }
    public var loop: Bool = false {// false ä¸å¾ªç¯æ’­æ”¾  true å¾ªç¯æ’­æ”¾
        didSet {
            if loop {
                remoteAudioPlayer?.actionAtItemEnd = .none
            } else {
                remoteAudioPlayer?.actionAtItemEnd = .pause
            }
        }
    }
    
    ///The default number of current cycles is 0
    private var currentNumberOfLoops: Int = 0
    
    public var numberOfLoops: Int = 1 {
        didSet {
            //reset to 0
            currentNumberOfLoops = 0
            remoteAudioPlayer?.actionAtItemEnd = .none
        }
    }
    
    public var track: String?
    
    // æ’­æ”¾è¿›åº¦ç›‘å¬
    private var _time_observer: Any? = nil
    //å½“å‰çš„ç½‘ç»œæ’­æ”¾åœ°å€
    private var _remoteAudioUrl: String = ""
    
    private var _pauseForEnterBackground: Bool = false
    
    
    //è·å–audioæ—¶é•¿
    private var duration: Double {
        get {
            if let audioPlayer = remoteAudioPlayer {
                //                let timeRange = audioPlayer.currentItem?.loadedTimeRanges.first?.timeRangeValue
                let duration = CMTimeGetSeconds(audioPlayer.currentItem?.duration ?? CMTime.zero)
                return duration
            }
            return 0
        }
    }
    
    /// æ˜¯å¦æ­£åœ¨æ’­æ”¾
    public var isPlaying: Bool {
        get {
            if case .Playing = self.status {
                return true
            }
            return false
        }
    }
    
    public override init() {
        super.init()
        self.remoteAudioPlayer = AVPlayer()
    }
    
    func addNotificationRX(playerItem: AVPlayerItem) {
        
        playerItem.rx.observeWeakly(AVPlayer.Status.self, "status").asObservable()
            .subscribe(onNext: {[weak self] (event) in
                guard let `self` = self else { return }
                if let status = event {
                    if status == AVPlayer.Status.readyToPlay {
                        self.status = PTAudioPlayerEvent.Playing(0)
                        self.playEventsBlock?(PTAudioPlayerEvent.Playing(self.duration))
                        self.remoteAudioPlayer?.play()
                        self.remoteAudioPlayer?.rate = self.playSpeed
                    } else if status == AVPlayer.Status.failed {
                        self.status = PTAudioPlayerEvent.Error("")
                        self.playEventsBlock?(PTAudioPlayerEvent.Error("AVPlayer.failed--\(String(describing: playerItem.error))"))
                        print("AVPlayer.error--\(String(describing: playerItem.error))")
                    }
                }
            }).disposed(by: self.disposeBag)
        
        // ç¼“å†²ä¸è¶³æš‚åœ
        playerItem.rx.observe(Bool.self, "playbackBufferEmpty").subscribe(onNext: { [weak self] (value) in
            guard let `self` = self else {return}
            if case .Playing = self.status  {
                self.status = PTAudioPlayerEvent.Waiting
                self.playEventsBlock?(PTAudioPlayerEvent.Waiting)
            }
        }).disposed(by: self.disposeBag)
        
        //ç¼“å†²å¯ä»¥æ’­æ”¾
        playerItem.rx.observe(Bool.self, "playbackLikelyToKeepUp").subscribe(onNext: { [weak self] (value) in
            guard let `self` = self else {return}
            if  case .Waiting = self.status  {
                self.status = PTAudioPlayerEvent.Playing(0)
                self.remoteAudioPlayer?.play()
                self.remoteAudioPlayer?.rate = self.playSpeed
                self.playEventsBlock?(PTAudioPlayerEvent.Playing(self.duration))
            }
        }).disposed(by: self.disposeBag)
        
        //        NotificationCenter.default.rx.notification(AVPlayerItem.newErrorLogEntryNotification)
        //            .subscribe(onNext: { (notic) in
        //                print("newErrorLogEntryNotification")
        //            }).disposed(by: self.disposeBag)
        //
        //        NotificationCenter.default.rx.notification(AVPlayerItem.failedToPlayToEndTimeNotification)
        //            .subscribe(onNext: { (notic) in
        //                print("failedToPlayToEndTimeNotification")
        //            }).disposed(by: self.disposeBag)
        
        self.remoteAudioPlayer?.replaceCurrentItem(with: playerItem)
        self.remoteAudioPlayer?.automaticallyWaitsToMinimizeStalling = false
        self.remoteAudioPlayer?.rate = self.playSpeed

        NotificationCenter.default.rx.notification(AVPlayerItem.didPlayToEndTimeNotification)
            .subscribe(onNext: { [weak self] (notic) in
                guard let self else {return}
                if (notic.object as? AVPlayerItem ?? nil) === playerItem {
                    if self.loop {
                        //æ— é™å¾ªç¯
                        guard numberOfLoops != 0 else {
                            if let playerItem: AVPlayerItem = notic.object as? AVPlayerItem {
                                playerItem.seek(to: CMTime.zero)
                            }
                            return
                        }
                        //æœ‰æ¬¡æ•°çš„å¾ªç¯ 0 1 2 end 3
                        currentNumberOfLoops += 1
                        guard currentNumberOfLoops < numberOfLoops else {
                            if case .Playing = self.status {
                                self.stop(true)
                            }
                            return
                        }
                        if let playerItem: AVPlayerItem = notic.object as? AVPlayerItem {
                            playerItem.seek(to: CMTime.zero)
                        }
                    } else {
                        if case .Playing = self.status {
                            self.stop(true)
                        }
                    }
                }
            }).disposed(by: self.disposeBag)
        
        NotificationCenter.default.rx.notification(AVPlayerItem.failedToPlayToEndTimeNotification)
            .subscribe(onNext: { [weak self] (notic) in
                guard let `self` = self else {return}
                if (notic.object as? AVPlayerItem ?? nil) === playerItem {
                    if case .Playing = self.status {
                        self.stop(true)
                    }
                }
            }).disposed(by: self.disposeBag)
        
        
        NotificationCenter.default.rx.notification(AVPlayerItem.playbackStalledNotification)
            .subscribe(onNext: { [weak self] (notic) in
                guard let `self` = self else {return}
                if (notic.object as? AVPlayerItem ?? nil) === playerItem {
                    if case .Playing = self.status {
                        self.status = PTAudioPlayerEvent.Error("")
                        self.playEventsBlock?(PTAudioPlayerEvent.Error("media did not arrive in time to continue playback -" +  (playerItem.error?.localizedDescription ?? "")))
                        self.stop(false)
                    }
                }
            }).disposed(by: self.disposeBag)
        
        NotificationCenter.default.rx.notification(AVAudioSession.interruptionNotification).subscribe(onNext: { [weak self] (notic) in
            guard let self else { return }
            interruptionTypeChanged(notic)
        }).disposed(by: self.disposeBag)
     
        NotificationCenter.default.rx.notification(AVAudioSession.routeChangeNotification).subscribe { [weak self] notic in
            guard let self else { return }
            routeChangeTyptChanged(notic)
        }.disposed(by: self.disposeBag)
    }
    
    /// æ’­æ”¾è¿›åº¦çš„ç›‘å¬
    public func addPeriodicTimer () {
        
        self.removePeriodicTimer()
        if self.remoteAudioPlayer != nil {
            _time_observer = self.remoteAudioPlayer?.addPeriodicTimeObserver(forInterval: CMTimeMake(value: 1, timescale: 10), queue: DispatchQueue.init(label: "audio.interval"), using: { (time) in
                DispatchQueue.main.async { [weak self] in
                    guard let `self` = self else {return}
                    guard case .Playing = self.status else {return}
                    self.playEventsBlock?(PTAudioPlayerEvent.TimeUpdate(time.seconds))
                }
            })
        }
    }
    
    public func removePeriodicTimer() {
        if let ob = _time_observer {
            if ((ob as? Timer) != nil) {
                var timer = ob as? Timer
                timer?.invalidate()
                timer = nil
                _time_observer = nil
            } else {
                self.remoteAudioPlayer?.removeTimeObserver(ob)
                _time_observer = nil
            }
        }
    }
    
    public func receviedEventEnterBackground() {
        var needPause = false
        if case .Playing = self.status  { needPause = true }
        if case .Waiting = self.status  { needPause = true }
        if needPause  {
            if self == PTAudioPlayer.shared {
                PTAudioPlayer.shared.stop(true)
            } else {
                self._pauseForEnterBackground = true
                self.pause()
            }
        }
    }
    
    func receviedEventEnterForeground() {
        if case .Pause = self.status , self._pauseForEnterBackground == true {
            self._pauseForEnterBackground = false
            self.resume()
        } else if case .Playing = self.status  {
            self.stop(true)
        }
    }
    
    ///  Audio session change notification
    func mediaChangeInterruptionType(begin: Bool) {
        if begin {
            receviedEventEnterBackground()
        } else {
            receviedEventEnterForeground()
        }
    }
    
    deinit {
        remoteAudioPlayer = nil
        self.stop()
        //        ZKLog("\(self) dealloc\(String(describing: remoteAudioPlayer))")
    }
}

/// éŸ³é¢‘é€šçŸ¥
//MARK: - audio notification
extension PTAudioPlayer {
    
    ///æ‰“æ–­
    @objc private func interruptionTypeChanged(_ nof:Notification) {
        
        guard let userInfo = nof.userInfo, let reasonValue = userInfo[AVAudioSessionInterruptionTypeKey] as? UInt else { return }
        
        switch reasonValue {
        case AVAudioSession.InterruptionType.began.rawValue://Began
            var isAnotherAudioSuspend = false //æ˜¯å¦æ˜¯è¢«å…¶ä»–éŸ³é¢‘ä¼šè¯æ‰“æ–­
            if #available(iOS 10.3, *) {
                if #available(iOS 14.5, *) {
                    // iOS 14.5ä¹‹åä½¿ç”¨InterruptionReasonKey
                    let reasonKey = userInfo[AVAudioSessionInterruptionReasonKey] as! UInt
                    switch reasonKey {
                    case AVAudioSession.InterruptionReason.default.rawValue:
                        //å› ä¸ºå¦ä¸€ä¸ªä¼šè¯è¢«æ¿€æ´»,éŸ³é¢‘ä¸­æ–­
                        isAnotherAudioSuspend = true
                        break
                    case AVAudioSession.InterruptionReason.appWasSuspended.rawValue:
                        //ç”±äºAPPè¢«ç³»ç»ŸæŒ‚èµ·ï¼ŒéŸ³é¢‘ä¸­æ–­ã€‚
                        break
                    case AVAudioSession.InterruptionReason.builtInMicMuted.rawValue:
                        //éŸ³é¢‘å› å†…ç½®éº¦å…‹é£é™éŸ³è€Œä¸­æ–­(ä¾‹å¦‚iPadæ™ºèƒ½å…³é—­å¥—iPad's Smart Folioå…³é—­)
                        break
                    default: break
                    }
                    print("AVAudioSessionInterruption: \(reasonKey)")
                } else {
                    // iOS10.3-14.5ï¼ŒInterruptionWasSuspendedKeyä¸ºtrueè¡¨ç¤ºä¸­æ–­æ˜¯ç”±äºç³»ç»ŸæŒ‚èµ·ï¼Œfalseæ˜¯è¢«å¦ä¸€éŸ³é¢‘æ‰“æ–­
                    let suspendedNumber:NSNumber = userInfo[AVAudioSessionInterruptionWasSuspendedKey] as! NSNumber
                    isAnotherAudioSuspend = !suspendedNumber.boolValue
                }
            }
            
            if isAnotherAudioSuspend {
                //                if (self.delegate != nil){
                mediaChangeInterruptionType(begin: true)
                print("mediaChangeInterruptionType: å¼€å§‹")
                //                }
            }
            break
        case AVAudioSession.InterruptionType.ended.rawValue://End
            let optionKey = userInfo[AVAudioSessionInterruptionOptionKey] as? UInt
            if optionKey == AVAudioSession.InterruptionOptions.shouldResume.rawValue {
                //æŒ‡ç¤ºå¦ä¸€ä¸ªéŸ³é¢‘ä¼šè¯çš„ä¸­æ–­å·²ç»“æŸï¼Œæœ¬åº”ç”¨ç¨‹åºå¯ä»¥æ¢å¤éŸ³é¢‘ã€‚
                //                if (self.delegate != nil){
                mediaChangeInterruptionType(begin: false)
                print("mediaChangeInterruptionType: ç»“æŸ")
                //                }
            }
            break
        default: break
        }
    }
    
    ///è€³æœº
    @objc private func routeChangeTyptChanged(_ nof:Notification) {
//        print("audio session route change \(nof)")
        
        guard let userInfo = nof.userInfo else { return }
        var seccReason = ""
        guard let reason = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt else {return}
        
        switch reason {
        case AVAudioSession.RouteChangeReason.newDeviceAvailable.rawValue:
            seccReason = "æœ‰æ–°è®¾å¤‡å¯ç”¨"
            // ä¸€èˆ¬ä¸ºæ¥å…¥äº†è€³æœº,å‚æ•°ä¸ºæ—§è®¾å¤‡çš„ä¿¡æ¯ã€‚
            guard let previousRoute = userInfo[AVAudioSessionRouteChangePreviousRouteKey] as? AVAudioSessionRouteDescription  else {
                return
            }
            if previousRoute.inputs.count <= 0 && previousRoute.outputs.count <= 0 {
                return
            }

            let previousOutput = previousRoute.outputs[0]
            let portType = previousOutput.portType
            print("éŸ³é¢‘æ¨¡å¼æ›´æ”¹:æœ‰æ–°è®¾å¤‡å¯ç”¨é€šçŸ¥- \(portType.rawValue)")
            if portType == AVAudioSession.Port.headphones {
                //åœ¨è¿™é‡Œæš‚åœæ’­æ”¾, æ›´æ”¹è¾“å‡ºè®¾å¤‡ï¼Œå½•éŸ³æ—¶èƒŒæ™¯éŸ³éœ€è¦é‡ç½®ã€‚å¦åˆ™æ— æ³•æ¶ˆéŸ³
                print("è€³æœºğŸ§æ¨¡å¼")
            } else if portType == AVAudioSession.Port.builtInSpeaker {
                print("Built-in speaker on an iOS device")
            }
        case AVAudioSession.RouteChangeReason.oldDeviceUnavailable.rawValue:
            seccReason = "è€è®¾å¤‡ä¸å¯ç”¨"
            guard let previousRoute = userInfo[AVAudioSessionRouteChangePreviousRouteKey] as? AVAudioSessionRouteDescription  else {
                return
            }
            if previousRoute.inputs.count <= 0 && previousRoute.outputs.count <= 0 {
                return
            }
            let previousOutput = previousRoute.outputs[0]
            let portType = previousOutput.portType
            print("éŸ³é¢‘æ¨¡å¼æ›´æ”¹:è€è®¾å¤‡ä¸å¯ç”¨é€šçŸ¥- \(portType.rawValue)")
            if portType == AVAudioSession.Port.headphones {
                print("è€³æœºğŸ§æ¨¡å¼")
                if isPlaying {
                    self.resume()
                }
            } else if portType == AVAudioSession.Port.builtInSpeaker {
                
            }
        case AVAudioSession.RouteChangeReason.categoryChange.rawValue:
            seccReason = "ç±»åˆ«Cagetoryæ”¹å˜äº†"
        case AVAudioSession.RouteChangeReason.override.rawValue:
            seccReason = "Appé‡ç½®äº†è¾“å‡ºè®¾ç½®"
        case AVAudioSession.RouteChangeReason.wakeFromSleep.rawValue:
            seccReason = "ä»ç¡çœ çŠ¶æ€å‘¼é†’"
        case AVAudioSession.RouteChangeReason.noSuitableRouteForCategory.rawValue:
            seccReason = "å½“å‰Categoryä¸‹æ²¡æœ‰åˆé€‚çš„è®¾å¤‡"
            
        case AVAudioSession.RouteChangeReason.routeConfigurationChange.rawValue:
            seccReason = "Rotuerçš„é…ç½®æ”¹å˜äº†"
//        case AVAudioSession.RouteChangeReason.unknown,
        default:
            seccReason = "æœªçŸ¥åŸå› "
        }
    }
}

extension PTAudioPlayer: GXAudioPlayerProtocol {
    
    public func play(url: String) {
        self.setAVAudioSession()
        status = PTAudioPlayerEvent.None
        
        let canUseCache = FileManager.default.fileExists(atPath: url)
        var audioUrl: URL?
        if canUseCache {
            var fileUrl : URL?
            if #available(iOS 16.0, *) {
                fileUrl = URL(filePath: url)
            } else {
                // Fallback on earlier versions
                fileUrl = URL(fileURLWithPath: url)
            }
            audioUrl = fileUrl
        } else {
            guard let escapedURLString = url.addingPercentEncoding(withAllowedCharacters: CharacterSet.urlQueryAllowed) else {
                return
            }
            audioUrl = URL(string: escapedURLString)
        }
        
        if let _url = audioUrl {
            self._remoteAudioUrl = url
            if self.remoteAudioPlayer == nil {
                self.remoteAudioPlayer = AVPlayer.init()
            } else {
                //                    self.disposeBag = DisposeBag()
            }
            remoteAudioPlayer?.pause()
//            self.playRemoteAudio(url: _url)
            let playerItem = AVPlayerItem.init(url: _url)
            self.addNotificationRX(playerItem: playerItem)
        } else {
            self.playEventsBlock?(PTAudioPlayerEvent.Error("urlå¼‚å¸¸ï¼š\(url)"))
        }
    }
    
    public func play(fileURL fileUrl: URL) {
        
    }
    
    /// æš‚åœæ’­æ”¾
    public func pause() {
        self.playEventsBlock?(PTAudioPlayerEvent.Pause)
        self.status = .Pause
        remoteAudioPlayer?.pause()
    }
    
    /// é‡æ–°æ’­æ”¾
    public func resume() {
        self.playEventsBlock?(.Playing(self.duration))
        self.status = .Playing(0)
        setAVAudioSession()
        remoteAudioPlayer?.rate = self.playSpeed
    }
    
    public func setSeekToTime(seconds: Double)  {
        //Â æ‹–åŠ¨æ”¹å˜æ’­æ”¾è¿›åº¦
        let targetTime: CMTime = CMTimeMake(value: Int64(seconds), timescale: 1)
        //æ’­æ”¾å™¨å®šä½åˆ°å¯¹åº”çš„ä½ç½®
        self.remoteAudioPlayer?.seek(to: targetTime)
    }
    
    public func stop() {
        stop(false)
    }
    
    /// åœæ­¢æ’­æ”¾
    public func stop(_ issue : Bool = false) {
        NotificationCenter.default.removeObserver(self)
        self.removePeriodicTimer()
        if issue {
            self.playEventsBlock?(.Ended)
        }
        self.status = .None
        remoteAudioPlayer?.pause()
        remoteAudioPlayer?.replaceCurrentItem(with: nil)
        //        self.remoteAudioPlayer = nil
        self.disposeBag = DisposeBag()
    }
}

extension PTAudioPlayer {
    func getDeviceOutputInfo(portType: AVAudioSession.Port) -> String {
        var type = ""
        switch portType {
        case .headsetMic:
            type = "headsetMic"
        case .builtInMic:
            type = "å†…ç½®éº¦å…‹é£"
        case .builtInSpeaker:
            type = "å†…ç½®æ‰¬å£°å™¨"
        case .headphones:
            type = "æ’çº¿è€³æœº"
        case .bluetoothA2DP:
            type = "è“ç‰™éŸ³é¢‘ä¼ è¾“æ¨¡å‹åè®®"
        case .bluetoothLE:
            type = "ä½åŠŸè€—è“ç‰™"
        case .airPlay:
            type = "éš”ç©ºæ’­æ”¾"
        
        default:
            type = "å†…ç½®æ‰¬å£°å™¨"
        }
        return type
    }
}
